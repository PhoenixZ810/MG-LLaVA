# Dataset Preparation

## Pretraining

During the image-based training stage, our dataset comprises 558K image-caption pairs
from LAION-CCSBU and 708k image-caption pairs from ALLaVA-4V-Caption dataset,
culminating in a total of 1.26M image-caption pairs for pretraining.

## Fine-tuning

The datasets employed for
instruction-tuning encompass 665K mixture dataset from LLaVA-Instruct, 692k instructions from
ALLaVA-4V-Instruction dataset, and an additional 25k instructions derived from a combination
of ShareGPT4V , DocVQA [ 63 ], DVQA [ 64 ] and AI2D [ 65 ], with a total number of more
than 1.3M image-text conversations.